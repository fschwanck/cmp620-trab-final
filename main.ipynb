{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import tarfile\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torchvision.models import (\n",
    "    resnet50, \n",
    "    ResNet50_Weights, \n",
    "    regnet_y_16gf, \n",
    "    RegNet_Y_16GF_Weights, \n",
    "    mobilenet_v3_large, \n",
    "    MobileNet_V3_Large_Weights, \n",
    "    vit_l_16, \n",
    "    ViT_L_16_Weights, \n",
    "    convnext_tiny, \n",
    "    ConvNeXt_Tiny_Weights,\n",
    "    vgg16, \n",
    "    VGG16_Weights, \n",
    "    swin_s, \n",
    "    Swin_S_Weights, \n",
    "    googlenet, \n",
    "    GoogLeNet_Weights, \n",
    "    efficientnet_b3, \n",
    "    EfficientNet_B3_Weights, \n",
    "    wide_resnet101_2, \n",
    "    Wide_ResNet101_2_Weights\n",
    ")\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./dataset\"\n",
    "DATA_PATH = \"./data\"\n",
    "RESULTS_PATH = \"./results\"\n",
    "DATASET = {\n",
    "    'test_files_url': 'https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar',\n",
    "    'test_files_tar': os.path.join(DATASET_PATH, 'ILSVRC2012_img_val.tar'),\n",
    "    'test_files': os.path.join(DATA_PATH, 'test_files'),\n",
    "    'ground_truth_url': 'http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz',\n",
    "    'ground_truth_tar_gz': os.path.join(DATASET_PATH, 'caffe_ilsvrc12.tar.gz'),\n",
    "    'ground_truth': DATA_PATH,\n",
    "    'ground_truth_file':  os.path.join(DATA_PATH, 'val.txt'),\n",
    "}\n",
    "LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')\n",
    "DEVICE = 'cpu'\n",
    "NUM_FILES = 10000\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_PATH, 'test_files'), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(class_name: str, log_level: str = LOG_LEVEL):\n",
    "    logging.basicConfig()\n",
    "    logger = logging.getLogger(class_name)\n",
    "    logger.setLevel(log_level)\n",
    "    return logger\n",
    "\n",
    "log = get_logger('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, output: str):\n",
    "    if not os.path.exists(output):    \n",
    "        with open(output, 'wb') as compressed_file:\n",
    "            log.info(f\"Downloading file: {url}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for chunk in response.iter_content(chunk_size=1024): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    compressed_file.write(chunk)\n",
    "        log.info(f\"Downloadedfile: {output}\")\n",
    "        return True\n",
    "    log.info(f\"File already exists: {output}\")\n",
    "    return False\n",
    "\n",
    "def extract_all_files(tar_file_path: str, extract_to: str):\n",
    "    with tarfile.open(tar_file_path, 'r') as tar:\n",
    "        log.info(f\"Extracting: {tar_file_path}\")\n",
    "        tar.extractall(extract_to)\n",
    "        log.info(f\"Extracted to: {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download(DATASET['test_files_url'], DATASET['test_files_tar'])\n",
    "#download(DATASET['ground_truth_url'], DATASET['ground_truth_tar_gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_all_files(DATASET['ground_truth_tar_gz'], DATASET['ground_truth'])\n",
    "#extract_all_files(DATASET['test_files_tar'], DATASET['test_files'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_files_dir = DATASET['test_files']\n",
    "ground_truth_file = DATASET['ground_truth_file']\n",
    "\n",
    "# Builds the filename_to_class dictionary, which will serve as a ground truth\n",
    "# The key is the filename, and the value is the ground truth class ID\n",
    "\n",
    "files = sorted([f for f in os.listdir(test_files_dir) if os.path.isfile(os.path.join(test_files_dir, f))])\n",
    "files = files[:NUM_FILES]\n",
    "filename_to_class = {}\n",
    "\n",
    "with open(ground_truth_file, 'r') as ground_truth:\n",
    "  i = 0\n",
    "  for line in ground_truth:\n",
    "    if (i == NUM_FILES):\n",
    "      break\n",
    "    filename_to_class[files[i]] = int(line.strip().split(' ')[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = [\n",
    "    {\n",
    "        'name': 'ResNet50',\n",
    "        'params': 25557032,\n",
    "        'gflops': 4.09,\n",
    "        'year': 2015,\n",
    "        'size': 97800000,\n",
    "        'model': resnet50,\n",
    "        'weights': ResNet50_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'RegNet Y 16GF',\n",
    "        'params': 83590140,\n",
    "        'gflops': 15.91,\n",
    "        'year': 2020,\n",
    "        'size': 319500000,\n",
    "        'model': regnet_y_16gf,\n",
    "        'weights': RegNet_Y_16GF_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'MobileNet V3 Large Weights',\n",
    "        'params': 5483032,\n",
    "        'gflops': 0.22,\n",
    "        'year': 2019,\n",
    "        'size': 21100000,\n",
    "        'model': mobilenet_v3_large,\n",
    "        'weights': MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'ViT L 16',\n",
    "        'params': 304326632,\n",
    "        'gflops': 61.55,\n",
    "        'year': 2021,\n",
    "        'size': 1161000000,\n",
    "        'model': vit_l_16,\n",
    "        'weights': ViT_L_16_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'ConvNeXt Tiny Weights',\n",
    "        'params': 28589128,\n",
    "        'gflops': 4.46,\n",
    "        'year': 2022,\n",
    "        'size': 109100000,\n",
    "        'model': convnext_tiny,\n",
    "        'weights': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'VGG 16',\n",
    "        'params': 138357544,\n",
    "        'gflops': 15.47,\n",
    "        'year': 2014,\n",
    "        'size': 527800000,\n",
    "        'model': vgg16,\n",
    "        'weights': VGG16_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'Swin S',\n",
    "        'params': 49606258,\n",
    "        'gflops': 8.74,\n",
    "        'year': 2021,\n",
    "        'size': 189800000,\n",
    "        'model': swin_s,\n",
    "        'weights': Swin_S_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'GoogLe Net',\n",
    "        'params': 6624904,\n",
    "        'gflops': 1.50,\n",
    "        'year': 2014,\n",
    "        'size': 49700000,\n",
    "        'model': googlenet,\n",
    "        'weights': GoogLeNet_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'Efficient Net B3',\n",
    "        'params': 12233232,\n",
    "        'gflops': 1.83,\n",
    "        'year': 2019,\n",
    "        'size': 47200000,\n",
    "        'model': efficientnet_b3,\n",
    "        'weights': EfficientNet_B3_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wide ResNet 101',\n",
    "        'params': 126886696,\n",
    "        'gflops': 22.75,\n",
    "        'year': 2016,\n",
    "        'size': 242900000,\n",
    "        'model': wide_resnet101_2,\n",
    "        'weights': Wide_ResNet101_2_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(metadata, weights):\n",
    "  torch.cuda.empty_cache()\n",
    "  model = metadata['model'](weights=weights)\n",
    "  model.to(DEVICE)\n",
    "  model.eval()\n",
    "  \n",
    "  # Step 2: Initialize the inference transforms\n",
    "  preprocess = weights.transforms()\n",
    "\n",
    "  right = 0\n",
    "  wrong = 0\n",
    "  time_elapsed: float = 0\n",
    "  data = [\n",
    "  ]\n",
    "\n",
    "\n",
    "  \n",
    "  for file in files:\n",
    "    img = Image.open(test_files_dir + '/' + file)\n",
    "\n",
    "    img = img.convert('RGB')\n",
    "   \n",
    "    start = time.time()\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "\n",
    "    # Step 4: Use the model and print the predicted category\n",
    "\n",
    "    prediction = model(batch).squeeze(0).softmax(0)\n",
    "    end = time.time()\n",
    "    time_elapsed = time_elapsed + (end - start)\n",
    "    class_id = prediction.argmax().item()\n",
    "    if (class_id == filename_to_class[file]):\n",
    "      right += 1\n",
    "    else:\n",
    "      wrong += 1\n",
    "    index = right + wrong\n",
    "    score = prediction[class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    if not (right + wrong) % 1000:\n",
    "      log.info(f'{index}\\tAccuracy: {right/(index)}')\n",
    "    data.append({\n",
    "      'index': index,\n",
    "      'accuracy': right/(index),\n",
    "      'inference_time': end - start,\n",
    "      'category_name': category_name,\n",
    "      'score': score,\n",
    "      'model': metadata['name'],\n",
    "      'device': DEVICE\n",
    "    })\n",
    "\n",
    "  # TODO: Return a tuple of (inference_time, accuracy) instead of just accuracy and populate the metadata with inference as well\n",
    "  # INFERENCE SHOULD BE AN AVERAGE PER PREDICTION, AND NOT THE SUM OF THEM ALL\n",
    "  accuracy = right/(index)\n",
    "  inference_avg = time_elapsed/(index)\n",
    "  return (accuracy, inference_avg, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metadata in model_metadata:\n",
    "  weights = metadata['weights']\n",
    "  \n",
    "  # Step 1: Initialize model with the best available weights\n",
    "\n",
    "  metadata['accuracy'], metadata['inference'], data = get_model_accuracy(metadata, weights)\n",
    "  df = pandas.DataFrame.from_records(data)\n",
    "  df.to_csv(os.path.join(RESULTS_PATH, f'{metadata[\"name\"]}-{DEVICE}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_records(model_metadata)\n",
    "df = df.drop('model', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(RESULTS_PATH, f'results-{DEVICE}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
