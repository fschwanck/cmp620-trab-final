{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import tarfile\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torchvision.models import (\n",
    "    resnet50, \n",
    "    ResNet50_Weights, \n",
    "    regnet_y_16gf, \n",
    "    RegNet_Y_16GF_Weights, \n",
    "    mobilenet_v3_large, \n",
    "    MobileNet_V3_Large_Weights, \n",
    "    vit_h_14, \n",
    "    ViT_H_14_Weights, \n",
    "    convnext_tiny, \n",
    "    ConvNeXt_Tiny_Weights\n",
    ")\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"./dataset\"\n",
    "DATA_PATH = \"./data\"\n",
    "DATASET = {\n",
    "    'test_files_url': 'https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar',\n",
    "    'test_files_tar': os.path.join(DATASET_PATH, 'ILSVRC2012_img_val.tar'),\n",
    "    'test_files': os.path.join(DATA_PATH, 'test_files'),\n",
    "    'ground_truth_url': 'http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz',\n",
    "    'ground_truth_tar_gz': os.path.join(DATASET_PATH, 'caffe_ilsvrc12.tar.gz'),\n",
    "    'ground_truth': DATA_PATH,\n",
    "    'ground_truth_file':  os.path.join(DATA_PATH, 'val.txt'),\n",
    "}\n",
    "LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_FILES = 50000\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_PATH, 'test_files'), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(class_name: str, log_level: str = LOG_LEVEL):\n",
    "    logging.basicConfig()\n",
    "    logger = logging.getLogger(class_name)\n",
    "    logger.setLevel(log_level)\n",
    "    return logger\n",
    "\n",
    "log = get_logger('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, output: str):\n",
    "    if not os.path.exists(output):    \n",
    "        with open(output, 'wb') as compressed_file:\n",
    "            log.info(f\"Downloading file: {url}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for chunk in response.iter_content(chunk_size=1024): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    compressed_file.write(chunk)\n",
    "        log.info(f\"Downloadedfile: {output}\")\n",
    "        return True\n",
    "    log.info(f\"File already exists: {output}\")\n",
    "    return False\n",
    "\n",
    "def extract_all_files(tar_file_path: str, extract_to: str):\n",
    "    with tarfile.open(tar_file_path, 'r') as tar:\n",
    "        log.info(f\"Extracting: {tar_file_path}\")\n",
    "        tar.extractall(extract_to)\n",
    "        log.info(f\"Extracted to: {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download(DATASET['test_files_url'], DATASET['test_files_tar'])\n",
    "#download(DATASET['ground_truth_url'], DATASET['ground_truth_tar_gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_all_files(DATASET['ground_truth_tar_gz'], DATASET['ground_truth'])\n",
    "#extract_all_files(DATASET['test_files_tar'], DATASET['test_files'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_files_dir = DATASET['test_files']\n",
    "ground_truth_file = DATASET['ground_truth_file']\n",
    "\n",
    "# Builds the filename_to_class dictionary, which will serve as a ground truth\n",
    "# The key is the filename, and the value is the ground truth class ID\n",
    "\n",
    "files = sorted([f for f in os.listdir(test_files_dir) if os.path.isfile(os.path.join(test_files_dir, f))])\n",
    "files = files[:NUM_FILES]\n",
    "filename_to_class = {}\n",
    "\n",
    "with open(ground_truth_file, 'r') as ground_truth:\n",
    "  i = 0\n",
    "  for line in ground_truth:\n",
    "    if (i == NUM_FILES):\n",
    "      break\n",
    "    filename_to_class[files[i]] = int(line.strip().split(' ')[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = [\n",
    "    {\n",
    "        'name': 'ResNet50',\n",
    "        'params': 25557032,\n",
    "        'gflops': 4.09,\n",
    "        'year': 2015,\n",
    "        'size': 97800000,\n",
    "        'model': resnet50,\n",
    "        'weights': ResNet50_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'RegNet_Y_16GF',\n",
    "        'params': 83590140,\n",
    "        'gflops': 15.91,\n",
    "        'year': 2020,\n",
    "        'size': 319500000,\n",
    "        'model': regnet_y_16gf,\n",
    "        'weights': RegNet_Y_16GF_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    {\n",
    "        'name': 'MobileNet_V3_Large_Weights',\n",
    "        'params': 5483032,\n",
    "        'gflops': 0.22,\n",
    "        'year': 2019,\n",
    "        'size': 21100000,\n",
    "        'model': mobilenet_v3_large,\n",
    "        'weights': MobileNet_V3_Large_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0\n",
    "    },\n",
    "    #{\n",
    "    #    'name': 'ViT_H_14',\n",
    "    #    'params': 633470440,\n",
    "    #    'gflops': 1016.72,\n",
    "    #    'year': 2021,\n",
    "    #    'size': 2416600000,\n",
    "    #    'model': vit_h_14,\n",
    "    #    'weights': ViT_H_14_Weights.DEFAULT,\n",
    "    #    'accuracy': 0,\n",
    "    #    'inference': 0\n",
    "    #},\n",
    "    {\n",
    "        'name': 'ConvNeXt_Tiny_Weights',\n",
    "        'params': 28589128,\n",
    "        'gflops': 4.46,\n",
    "        'year': 2022,\n",
    "        'size': 109100000,\n",
    "        'model': convnext_tiny,\n",
    "        'weights': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "        'accuracy': 0,\n",
    "        'inference': 0,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(metadata, weights):\n",
    "  torch.cuda.empty_cache()\n",
    "  model = metadata['model'](weights=weights)\n",
    "  model.to(DEVICE)\n",
    "  model.eval()\n",
    "  \n",
    "  # Step 2: Initialize the inference transforms\n",
    "  preprocess = weights.transforms()\n",
    "\n",
    "  right = 0\n",
    "  wrong = 0\n",
    "  time_elapsed: float = 0\n",
    "  data = [\n",
    "  ]\n",
    "\n",
    "\n",
    "  \n",
    "  for file in files:\n",
    "    img = Image.open(test_files_dir + '/' + file)\n",
    "\n",
    "    img = img.convert('RGB')\n",
    "   \n",
    "    start = time.time()\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "\n",
    "    # Step 4: Use the model and print the predicted category\n",
    "\n",
    "    prediction = model(batch).squeeze(0).softmax(0)\n",
    "    end = time.time()\n",
    "    time_elapsed = time_elapsed + (end - start)\n",
    "    class_id = prediction.argmax().item()\n",
    "    if (class_id == filename_to_class[file]):\n",
    "      right += 1\n",
    "    else:\n",
    "      wrong += 1\n",
    "    index = right + wrong\n",
    "    score = prediction[class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    if not (right + wrong) % 1000:\n",
    "      log.info(f'{index}\\tAccuracy: {right/(index)}')\n",
    "    data.append({\n",
    "      'index': index,\n",
    "      'accuracy': right/(index),\n",
    "      'inference_time': end - start,\n",
    "      'category_name': category_name,\n",
    "      'score': score,\n",
    "      'model': metadata['name']\n",
    "    })\n",
    "\n",
    "  # TODO: Return a tuple of (inference_time, accuracy) instead of just accuracy and populate the metadata with inference as well\n",
    "  # INFERENCE SHOULD BE AN AVERAGE PER PREDICTION, AND NOT THE SUM OF THEM ALL\n",
    "  accuracy = right/(index)\n",
    "  inference_avg = time_elapsed/(index)\n",
    "  return (accuracy, inference_avg, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:main:1000\tAccuracy: 0.801\n",
      "INFO:main:1000\tAccuracy: 0.826\n",
      "INFO:main:1000\tAccuracy: 0.751\n",
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /home/fschwanck/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
      "100.0%\n",
      "INFO:main:1000\tAccuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "for metadata in model_metadata:\n",
    "  weights = metadata['weights']\n",
    "  \n",
    "  # Step 1: Initialize model with the best available weights\n",
    "\n",
    "  metadata['accuracy'], metadata['inference'], data = get_model_accuracy(metadata, weights)\n",
    "  df = pandas.DataFrame.from_records(data)\n",
    "  df.to_csv(f'{metadata[\"name\"]}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>params</th>\n",
       "      <th>gflops</th>\n",
       "      <th>year</th>\n",
       "      <th>size</th>\n",
       "      <th>weights</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>25557032</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2015</td>\n",
       "      <td>97800000</td>\n",
       "      <td>ResNet50_Weights.IMAGENET1K_V2</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.009014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RegNet_Y_16GF</td>\n",
       "      <td>83590140</td>\n",
       "      <td>15.91</td>\n",
       "      <td>2020</td>\n",
       "      <td>319500000</td>\n",
       "      <td>RegNet_Y_16GF_Weights.IMAGENET1K_V2</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.014883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MobileNet_V3_Large_Weights</td>\n",
       "      <td>5483032</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2019</td>\n",
       "      <td>21100000</td>\n",
       "      <td>MobileNet_V3_Large_Weights.IMAGENET1K_V2</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.011017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_Tiny_Weights</td>\n",
       "      <td>28589128</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2022</td>\n",
       "      <td>109100000</td>\n",
       "      <td>ConvNeXt_Tiny_Weights.IMAGENET1K_V1</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.006469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name    params  gflops  year       size  \\\n",
       "0                    ResNet50  25557032    4.09  2015   97800000   \n",
       "1               RegNet_Y_16GF  83590140   15.91  2020  319500000   \n",
       "2  MobileNet_V3_Large_Weights   5483032    0.22  2019   21100000   \n",
       "3       ConvNeXt_Tiny_Weights  28589128    4.46  2022  109100000   \n",
       "\n",
       "                                    weights  accuracy  inference  \n",
       "0            ResNet50_Weights.IMAGENET1K_V2     0.801   0.009014  \n",
       "1       RegNet_Y_16GF_Weights.IMAGENET1K_V2     0.826   0.014883  \n",
       "2  MobileNet_V3_Large_Weights.IMAGENET1K_V2     0.751   0.011017  \n",
       "3       ConvNeXt_Tiny_Weights.IMAGENET1K_V1     0.819   0.006469  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame.from_records(model_metadata)\n",
    "df.drop('model', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
